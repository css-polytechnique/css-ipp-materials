{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PeOBaZTWyIS"
      },
      "source": [
        "# Extract information with LLM\n",
        "\n",
        "Colab notebook written by Emma Bonutti D'Agostini and Emilien Schultz, June 2025."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEPYHftaWU1j"
      },
      "source": [
        "## Install and import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qMeSvb7VXrL",
        "outputId": "ade2e435-84f5-441d-a88a-bbcc6d8cfdb1"
      },
      "outputs": [],
      "source": [
        "# Install\n",
        "!pip install -q tqdm pandas scikit-learn openapi openai Levenshtein openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P7LOcKBtWWvF"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GYd0SP-Q7Gr",
        "outputId": "65d3015d-7bdb-4e95-ac93-fecdf8e026c2"
      },
      "outputs": [],
      "source": [
        "# If you are working with Colab, connect this notebook to your personal Google Drive account\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFonmutXgO2L"
      },
      "source": [
        "## Define request functions\n",
        "\n",
        "We use open router to prompt different models. We will need to enter our **key**.\n",
        "\n",
        "We will use meta-llama/llama-3.3-70b-instruct which is both efficient and cheap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCGiT5CARx8o"
      },
      "outputs": [],
      "source": [
        "# Define a function to make requests to the API\n",
        "\n",
        "token_or = \"YOUR KEY\" # INSERT YOUR KEY HERE\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=token_or,\n",
        ")\n",
        "\n",
        "def do_predictions(prompt_generator, texts, model = \"meta-llama/llama-3.3-70b-instruct\"):\n",
        "    \"\"\"\n",
        "    Run a prompt generator on a list of text for a specific model\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    total = len(texts)\n",
        "    with tqdm(total=total, desc=\"Progress\", unit='item',\n",
        "              bar_format='{l_bar}{bar} | {n_fmt}/{total_fmt} [{percentage:3.0f}%]') as pbar:\n",
        "        for i, j in texts.items():\n",
        "            try:\n",
        "                completion = client.chat.completions.create(\n",
        "                    model=model,\n",
        "                    messages=prompt_generator(j)\n",
        "                )\n",
        "                results.append(completion)\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                results.append(None)\n",
        "            pbar.update(1)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_RYpcqOxBSF"
      },
      "source": [
        "Small test to see if everythings works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BByFy7MVRPfe",
        "outputId": "4e8c9c6b-1896-4b9b-d038-ec1e5d77b64b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='gen-1757939121-vY4ClgiDvsvKO6xWzlKu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A joke about computational social science! Here\\'s one:\\n\\nWhy did the computational social scientist break up with his girlfriend?\\n\\nBecause he realized their relationship was just a weak tie in a large network, and his sentiment analysis kept showing a decline in positive emotions. He tried to optimize their communication using natural language processing, but it was just a latency issue – she was always responding slowly to his messages! In the end, he decided to terminate the relationship, citing \"insufficient convergence\" and a lack of \"emergent behavior\" in their interactions. Now, he\\'s just a node in a singles\\' network, searching for a stronger connection... \\n\\nHope that one computed a smile!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='stop')], created=1757939121, model='meta-llama/llama-3.3-70b-instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=137, prompt_tokens=21, total_tokens=158, completion_tokens_details=None, prompt_tokens_details=None), provider='Crusoe')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# With the second model\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/llama-3.3-70b-instruct\",\n",
        "    messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Could you make a joke on computational social science ?\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlY9kc2PWsp3"
      },
      "source": [
        "# Information extraction\n",
        "Partial replication of \"From Codebooks to Promptbooks\" (Stuhler, Ton and Ollion 2025).\n",
        "\n",
        "- link to [paper](https://journals.sagepub.com/eprint/T3QXU8KV5BP5QYKZTDZI/full)\n",
        "- link to [replication materials](https://osf.io/hwuvs/)\n",
        "\n",
        "The obituaries analyzed in the paper are a synthetic sample - i.e. they are not real obituaties, but generated by AI on the model of NYT obituaries.\n",
        "\n",
        "Again, we will work with a sample of 100 texts to avoid making too many requests.\n",
        "\n",
        "We will replicate together the information extraction for gender (categorical) and educational instution (open field) attended."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbjvIe6cYesD"
      },
      "source": [
        "## Dataset\n",
        "Let's look at how typical obituaries look, at how the information of interest is presented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DH33ugPmX5Wd",
        "outputId": "3bfc2152-52f1-491b-f3f5-e29839947731"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>nid</th>\n",
              "      <th>gender</th>\n",
              "      <th>name</th>\n",
              "      <th>birth_month</th>\n",
              "      <th>birth_day</th>\n",
              "      <th>birth_year</th>\n",
              "      <th>occup</th>\n",
              "      <th>occup_elaborate</th>\n",
              "      <th>children</th>\n",
              "      <th>...</th>\n",
              "      <th>milit</th>\n",
              "      <th>birth</th>\n",
              "      <th>raised</th>\n",
              "      <th>last_lived</th>\n",
              "      <th>place_death</th>\n",
              "      <th>Religion</th>\n",
              "      <th>text</th>\n",
              "      <th>text_tok</th>\n",
              "      <th>text_char</th>\n",
              "      <th>text_combined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>man</td>\n",
              "      <td>John Deer</td>\n",
              "      <td>July</td>\n",
              "      <td>12</td>\n",
              "      <td>1944</td>\n",
              "      <td>Geneticist</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>Anaheim, California</td>\n",
              "      <td>the same place as they were born in</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>Stanford Health Care-Stanford Hospital</td>\n",
              "      <td>none mentioned</td>\n",
              "      <td>John Deer, a pioneering geneticist whose groun...</td>\n",
              "      <td>602</td>\n",
              "      <td>3556</td>\n",
              "      <td>Date: October 1st, 2024\\nObituary: John Deer, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>101</td>\n",
              "      <td>man</td>\n",
              "      <td>John Deer</td>\n",
              "      <td>May</td>\n",
              "      <td>3</td>\n",
              "      <td>1942</td>\n",
              "      <td>Forensic Scientist</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>Providence , Rhode Island</td>\n",
              "      <td>the same place as they were born in</td>\n",
              "      <td>New York</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none mentioned</td>\n",
              "      <td>John Deer, a distinguished forensic scientist ...</td>\n",
              "      <td>486</td>\n",
              "      <td>2748</td>\n",
              "      <td>Date: October 1st, 2024\\nObituary: John Deer, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>man</td>\n",
              "      <td>John Deer</td>\n",
              "      <td>February</td>\n",
              "      <td>12</td>\n",
              "      <td>1901</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>WWI</td>\n",
              "      <td>Chicago, Illinois</td>\n",
              "      <td>Arlington, Texas</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>in an elderly care facility</td>\n",
              "      <td>none mentioned</td>\n",
              "      <td>John Deer, a revered engineer known for his in...</td>\n",
              "      <td>474</td>\n",
              "      <td>2715</td>\n",
              "      <td>Date: October 1st, 2024\\nObituary: John Deer, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>115</td>\n",
              "      <td>man</td>\n",
              "      <td>John Deer</td>\n",
              "      <td>August</td>\n",
              "      <td>10</td>\n",
              "      <td>1900</td>\n",
              "      <td>Neurosurgeon</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>WWI</td>\n",
              "      <td>Jackson, Mississippi</td>\n",
              "      <td>the same place as they were born in</td>\n",
              "      <td>Phoenix</td>\n",
              "      <td>UCLA Medical Center – Los Angeles</td>\n",
              "      <td>none mentioned</td>\n",
              "      <td>John Deer, a pioneering neurosurgeon renowned ...</td>\n",
              "      <td>514</td>\n",
              "      <td>2929</td>\n",
              "      <td>Date: October 1st, 2024\\nObituary: John Deer, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>man</td>\n",
              "      <td>John Deer</td>\n",
              "      <td>July</td>\n",
              "      <td>9</td>\n",
              "      <td>1932</td>\n",
              "      <td>Medical doctor</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>WWII</td>\n",
              "      <td>Arlington, Texas</td>\n",
              "      <td>the same place as they were born in</td>\n",
              "      <td>New York</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none mentioned</td>\n",
              "      <td>John Deer, a dedicated medical doctor who touc...</td>\n",
              "      <td>470</td>\n",
              "      <td>2506</td>\n",
              "      <td>Date: October 1st, 2024\\nObituary: John Deer, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  nid gender       name birth_month  birth_day  birth_year  \\\n",
              "0           1   52    man  John Deer        July         12        1944   \n",
              "1           2  101    man  John Deer         May          3        1942   \n",
              "2           3    3    man  John Deer    February         12        1901   \n",
              "3           4  115    man  John Deer      August         10        1900   \n",
              "4           5    1    man  John Deer        July          9        1932   \n",
              "\n",
              "                occup  occup_elaborate children  ...    milit  \\\n",
              "0          Geneticist                2        1  ...  Vietnam   \n",
              "1  Forensic Scientist                1        0  ...  Vietnam   \n",
              "2            Engineer                3        2  ...      WWI   \n",
              "3        Neurosurgeon                5        2  ...      WWI   \n",
              "4      Medical doctor                1        3  ...     WWII   \n",
              "\n",
              "                       birth                               raised  \\\n",
              "0        Anaheim, California  the same place as they were born in   \n",
              "1  Providence , Rhode Island  the same place as they were born in   \n",
              "2          Chicago, Illinois                    Arlington, Texas    \n",
              "3      Jackson, Mississippi   the same place as they were born in   \n",
              "4          Arlington, Texas   the same place as they were born in   \n",
              "\n",
              "      last_lived                             place_death        Religion  \\\n",
              "0  Los Angeles    Stanford Health Care-Stanford Hospital  none mentioned   \n",
              "1     New York                                       NaN  none mentioned   \n",
              "2      Chicago               in an elderly care facility  none mentioned   \n",
              "3      Phoenix         UCLA Medical Center – Los Angeles  none mentioned   \n",
              "4     New York                                       NaN  none mentioned   \n",
              "\n",
              "                                                text text_tok text_char  \\\n",
              "0  John Deer, a pioneering geneticist whose groun...      602      3556   \n",
              "1  John Deer, a distinguished forensic scientist ...      486      2748   \n",
              "2  John Deer, a revered engineer known for his in...      474      2715   \n",
              "3  John Deer, a pioneering neurosurgeon renowned ...      514      2929   \n",
              "4  John Deer, a dedicated medical doctor who touc...      470      2506   \n",
              "\n",
              "                                       text_combined  \n",
              "0  Date: October 1st, 2024\\nObituary: John Deer, ...  \n",
              "1  Date: October 1st, 2024\\nObituary: John Deer, ...  \n",
              "2  Date: October 1st, 2024\\nObituary: John Deer, ...  \n",
              "3  Date: October 1st, 2024\\nObituary: John Deer, ...  \n",
              "4  Date: October 1st, 2024\\nObituary: John Deer, ...  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://github.com/css-polytechnique/css-ipp-materials/raw/refs/heads/main/Python-tutorials/SICSS-2025/information-extraction/20241009_Synthetic300.csv\"\n",
        "obits = pd.read_csv(url)\n",
        "def combine_date_title_and_text(row : pd.Series):\n",
        "    return f\"Date: {row[\"date_death\"]}\\nObituary: {row[\"text\"]}\"\n",
        "\n",
        "obits[\"text_combined\"] = obits.apply(combine_date_title_and_text, axis = 1)\n",
        "obits.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ENS8Te25bh2D",
        "outputId": "cb8e717f-ed88-4607-808f-93cd8127b0a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Date: October 1st, 2024\\nObituary: John Deer, a dedicated auditor known for his meticulous attention to detail and unwavering integrity, passed away on October 7th, 2024, at the UCSF Medical Center in California. He was born on December 5, 1919, in Simi Valley, California, and was raised in the same nurturing community that shaped his values and principles.\\n\\nMr. Deer attended Yale, where he pursued his passion for numbers and finance, ultimately earning his college degree. Before his time at Yale, he attended a local high school where his exceptional academic abilities first caught the attention of his teachers. This early recognition of his potential set the stage for a lifetime of accomplishments in the field of auditing.\\n\\nDuring World War II, John bravely served his country with honor and distinction, embodying the spirit of sacrifice and commitment that defined his generation. His military service instilled in him a sense of duty and camaraderie that stayed with him throughout his life, influencing his approach to work and relationships.\\n\\nAs an auditor, John Deer excelled in his profession, earning a reputation for his sharp analytical skills and ethical conduct. Colleagues often sought his guidance and expertise, recognizing him as a mentor and a role model in the industry. His dedication to upholding the highest standards of accountability and transparency earned him the respect and admiration of all who had the privilege of working with him.\\n\\nIn addition to his successful career, John was a loving husband to his wife of many years and a devoted father to his only child. Family was at the center of his life, and he cherished the moments spent with his loved ones, creating lasting memories that will be treasured for generations to come.\\n\\nAn active member of the Mormon faith, John Deer found solace and guidance in his spiritual beliefs, which provided him with strength and comfort during life's challenges. His faith was a source of inspiration for those around him, shining through in his compassion and generosity towards others.\\n\\nIn reflecting on John's life, three anecdotes come to mind that capture the essence of the man behind the professional facade. He was known for his dry wit and subtle humor, always ready with a quick quip to lighten the mood during tense moments at work. His love for gardening was a well-kept secret among his colleagues, who were surprised to learn of his green thumb and the bountiful harvests he enjoyed each season. And finally, his penchant for classic literature, particularly Shakespearean plays, revealed a hidden depth to his character that few had the privilege of glimpsing.\\n\\nJohn Deer's legacy as a dedicated auditor, loving family man, and faithful servant will endure in the hearts of those who knew and loved him. His contributions to his profession and community leave a lasting impact that will be remembered with gratitude and respect. May he rest in peace, knowing that his life was a testament to hard work, integrity, and the enduring power of faith and family.\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obits['text_combined'].iloc[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaHEn2jWzCp_"
      },
      "source": [
        "We will extract different pieces of information:\n",
        "\n",
        "- gender (categorical variable)\n",
        "- educational degree (trickier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEWJlLfd4Z-w"
      },
      "source": [
        "Comment : obitaries are long texts: cost will be higher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncnoYTIqXyu7"
      },
      "source": [
        "## Replication for Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukvKd2M3c7dk",
        "outputId": "0111b5a3-85d7-4485-f3cc-9644893f62a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are a highly efficient information detection and extraction engine, specialized in analyzing natural language data.\\nYou value accuracy: when the user asks you to extract certain information from given text data, you will try your best to adhere to what is directly mentioned in the text and the extraction criteria.\\nYou value efficiency: your responses will be very concise, because they will be stored as values in a dataset. These responses will also strictly follow formatting conventions specified in the extraction prompt. '},\n",
              " {'role': 'user',\n",
              "  'content': \"Below I will provide an obituary of a deceased person.\\nBased on the text, infer the gender of the deceased person. Provide a one-word response from only one of the following options: 'man', 'woman', 'other'.\\n\\nThe text : Date: October 1st, 2024\\nObituary: John Deer, a distinguished forensic scientist known for his groundbreaking work in criminal investigations, passed away on October 7th, 2024, at his home in New York. He was 82 years old.\\n\\nBorn on May 3, 1942, in Providence, Rhode Island, John showed an early interest in the intricacies of science. Raised in the same city where he was born, he attended Bowdoin College, where he excelled in his studies, ultimately obtaining a college diploma.\\n\\nDeer's career as a forensic scientist was marked by his unwavering commitment to seeking justice through evidence-based investigations. His keen attention to detail and analytical skills helped solve numerous complex cases, earning him a reputation as a pioneer in his field. One of his notable contributions was the development of a new DNA analysis technique that revolutionized forensic procedures.\\n\\nDuring his time in Vietnam, where he served in the military, John Deer demonstrated courage and dedication to his duties, receiving commendations for his service. His experiences in the field further honed his investigative skills, shaping his future endeavors.\\n\\nDespite his professional achievements, John was a humble and kind-hearted individual, known for his wit and sense of humor. He had a passion for woodworking and often spent his free time creating intricate pieces of furniture for his loved ones. His meticulous craftsmanship and attention to detail were evident in every piece he crafted, reflecting his precise and methodical nature.\\n\\nIn his personal life, John was a devoted stepfather to his stepdaughter, Sarah, whom he cherished as his own. Although he did not have any biological children, he formed deep and meaningful bonds with his extended family and friends, who remember him fondly for his warmth and generosity.\\n\\nJohn Deer's sudden passing due to complications of a stroke has left a void in the forensic science community and among those who knew him. His legacy of integrity, professionalism, and dedication to his work will continue to inspire future generations of forensic scientists.\\n\\nIn remembrance of John, his colleagues and loved ones recall the countless times he shared his expertise with aspiring young scientists and mentored them with patience and encouragement. His commitment to excellence and his willingness to guide others in their professional journeys made him a beloved figure in the forensic science community.\\n\\nAs we bid farewell to John Deer, we celebrate a life well-lived, rich with accomplishments and milestones that have left an indelible mark on the field of forensic science. He will be deeply missed by all who had the privilege of knowing him, but his legacy will endure through the continued impact of his work and the lives he touched.\"}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Function to build the prompt: system, user, + text to process (passed as argument)\n",
        "\n",
        "prompt_system = (\"You are a highly efficient information detection and extraction engine, specialized in analyzing natural language data.\\n\"\n",
        "    \"You value accuracy: when the user asks you to extract certain information from given text data, you will try your best to adhere to what is directly mentioned in the text and the extraction criteria.\\n\"\n",
        "    \"You value efficiency: your responses will be very concise, because they will be stored as values in a dataset. These responses will also strictly follow formatting conventions specified in the extraction prompt. \")\n",
        "\n",
        "def prompt_user_gender(text):\n",
        "    #Text of the system prompt\n",
        "    return [\n",
        "       {\"role\":\"system\",\"content\":prompt_system},\n",
        "       {\"role\":\"user\",\"content\": \"Below I will provide an obituary of a deceased person.\\n\" +\n",
        "        \"Based on the text, infer the gender of the deceased person. Provide a one-word response from only one of the following options: 'man', 'woman', 'other'.\" +\n",
        "        f\"\\n\\nThe text : {text}\"}]\n",
        "\n",
        "# Check if the prompt is correct\n",
        "prompt_user_gender(obits.loc[1,\"text_combined\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbcO1QXPbkxN"
      },
      "source": [
        "Careful: inference can take several minutes (around 3). For this reason let's  use only a sample of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3kcMlC0BCajk"
      },
      "outputs": [],
      "source": [
        "# Create a sample to test\n",
        "N_max = 10\n",
        "df = obits[0:N_max]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa9AaxEWCgHz"
      },
      "source": [
        "And run the prompt on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "JbyFeGFa25-b",
        "outputId": "cf68c257-9b35-4801-c095-5e433f5ab1b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Progress: 100%|██████████ | 10/10 [100%]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>gender_llama33</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  gender gender_llama33\n",
              "0    man            man\n",
              "1    man            man\n",
              "2    man            man\n",
              "3    man            man\n",
              "4    man            man\n",
              "5    man            man\n",
              "6    man            man\n",
              "7    man            man\n",
              "8    man            man\n",
              "9    man            man"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run the prompts\n",
        "r_llama33 = do_predictions(prompt_user_gender,\n",
        "                           df['text_combined'],\n",
        "                           \"meta-llama/llama-3.3-70b-instruct\" #test with a different model\n",
        "                           )\n",
        "# Add the result to the dataframe\n",
        "df.loc[:, \"gender_llama33\"] = [i.choices[0].message.content if i is not None else None for i in r_llama33] #same for the second model tested\n",
        "\n",
        "# Save the data\n",
        "df.to_csv(\"table_results.csv\")\n",
        "\n",
        "# Display\n",
        "df[[\"gender\", \"gender_llama33\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtDkKZkWCerX"
      },
      "source": [
        "It works pretty well ! Let's get the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEH6julEEGVJ",
        "outputId": "90a624d6-87ee-4602-d928-4c65c18aca92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(1.0)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(df[\"gender\"] == df[\"gender_llama33\"]).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhKANDQhYms0"
      },
      "source": [
        "## Replicate for Educational Institution Attended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhX2pWZNWkz_",
        "outputId": "8e07b7eb-fc9c-4b5b-b568-f43c15586868"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are a highly efficient information detection and extraction engine, specialized in analyzing natural language data.\\nYou value accuracy: when the user asks you to extract certain information from given text data, you will try your best to adhere to what is directly mentioned in the text and the extraction criteria.\\nYou value efficiency: your responses will be very concise, because they will be stored as values in a dataset. These responses will also strictly follow formatting conventions specified in the extraction prompt. '},\n",
              " {'role': 'user',\n",
              "  'content': \"Below I will provide an obituary of a deceased person.\\nRecord all institutions of higher education that the person obtained a degree from (i.e., universities, colleges, or graduate & professional schools), exactly as written in the text. If the text indicates that this person attended some institution as a student, but did not complete their degree, record this institution as well. When giving your response, consider the following rules:\\n1) Do not include high schools or college preparatory schools.\\n2) Do not include institutions that the person’s friends, family, coworkers or partners attended, unless the deceased person also attended them.\\n3) Obituaries may describe decedents who were employed at academic institutions, such as instructors, scientists, university administrators and coaches. You must distinguish higher education institutions that this person studied at from those that this person worked at. Only institutions where the person studied should be considered in your response. Do not record higher education institutions only because the person worked, taught, or held a job there. For example, if the text says “after transferring from University 1 to study mathematics at University 2, he eventually got a master's degree from University 3. He became a head coach at University 4 and taught sports science at University 5”, your response should only include Universities 1, 2 and 3, but not University 4.\\n4) If universities are famously know with it's initials, give them instead of the full name (i.e. MIT for Massachusetts Institute of Technology)\\nIf the text does not mention any institutions of higher education that the person attended, simply respond with “none”.\\nIf your response is a list of two or more institutions, please separate each institution with a comma (e.g.: 'university 1, university 2, university 3').\\n\\nThe text : Date: October 1st, 2024\\nObituary: John Deer, a distinguished forensic scientist known for his groundbreaking work in criminal investigations, passed away on October 7th, 2024, at his home in New York. He was 82 years old.\\n\\nBorn on May 3, 1942, in Providence, Rhode Island, John showed an early interest in the intricacies of science. Raised in the same city where he was born, he attended Bowdoin College, where he excelled in his studies, ultimately obtaining a college diploma.\\n\\nDeer's career as a forensic scientist was marked by his unwavering commitment to seeking justice through evidence-based investigations. His keen attention to detail and analytical skills helped solve numerous complex cases, earning him a reputation as a pioneer in his field. One of his notable contributions was the development of a new DNA analysis technique that revolutionized forensic procedures.\\n\\nDuring his time in Vietnam, where he served in the military, John Deer demonstrated courage and dedication to his duties, receiving commendations for his service. His experiences in the field further honed his investigative skills, shaping his future endeavors.\\n\\nDespite his professional achievements, John was a humble and kind-hearted individual, known for his wit and sense of humor. He had a passion for woodworking and often spent his free time creating intricate pieces of furniture for his loved ones. His meticulous craftsmanship and attention to detail were evident in every piece he crafted, reflecting his precise and methodical nature.\\n\\nIn his personal life, John was a devoted stepfather to his stepdaughter, Sarah, whom he cherished as his own. Although he did not have any biological children, he formed deep and meaningful bonds with his extended family and friends, who remember him fondly for his warmth and generosity.\\n\\nJohn Deer's sudden passing due to complications of a stroke has left a void in the forensic science community and among those who knew him. His legacy of integrity, professionalism, and dedication to his work will continue to inspire future generations of forensic scientists.\\n\\nIn remembrance of John, his colleagues and loved ones recall the countless times he shared his expertise with aspiring young scientists and mentored them with patience and encouragement. His commitment to excellence and his willingness to guide others in their professional journeys made him a beloved figure in the forensic science community.\\n\\nAs we bid farewell to John Deer, we celebrate a life well-lived, rich with accomplishments and milestones that have left an indelible mark on the field of forensic science. He will be deeply missed by all who had the privilege of knowing him, but his legacy will endure through the continued impact of his work and the lives he touched.\"}]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We use the same system prompt but define a new user prompt\n",
        "def prompt_user_educinstit(text):\n",
        "  return [\n",
        "       {\"role\":\"system\",\"content\":prompt_system},\n",
        "       {\"role\":\"user\",\"content\": \"\"\"Below I will provide an obituary of a deceased person.\n",
        "Record all institutions of higher education that the person obtained a degree from (i.e., universities, colleges, or graduate & professional schools), exactly as written in the text. If the text indicates that this person attended some institution as a student, but did not complete their degree, record this institution as well. When giving your response, consider the following rules:\n",
        "1) Do not include high schools or college preparatory schools.\n",
        "2) Do not include institutions that the person’s friends, family, coworkers or partners attended, unless the deceased person also attended them.\n",
        "3) Obituaries may describe decedents who were employed at academic institutions, such as instructors, scientists, university administrators and coaches. You must distinguish higher education institutions that this person studied at from those that this person worked at. Only institutions where the person studied should be considered in your response. Do not record higher education institutions only because the person worked, taught, or held a job there. For example, if the text says “after transferring from University 1 to study mathematics at University 2, he eventually got a master's degree from University 3. He became a head coach at University 4 and taught sports science at University 5”, your response should only include Universities 1, 2 and 3, but not University 4.\n",
        "4) If universities are famously know with it's initials, give them instead of the full name (i.e. MIT for Massachusetts Institute of Technology)\n",
        "If the text does not mention any institutions of higher education that the person attended, simply respond with “none”.\n",
        "If your response is a list of two or more institutions, please separate each institution with a comma (e.g.: 'university 1, university 2, university 3').\"\"\" +\n",
        "f\"\\n\\nThe text : {text}\"}]\n",
        "\n",
        "prompt_user_educinstit(obits.loc[1,\"text_combined\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "KortiBcd5d3c",
        "outputId": "76712fe2-5d5c-49fa-98b7-beb002406c37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Progress: 100%|██████████ | 10/10 [100%]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>educ_inst</th>\n",
              "      <th>education_institution_llama33</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>University of California, Berkeley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bowndoin College</td>\n",
              "      <td>Bowdoin College</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cornell</td>\n",
              "      <td>MIT, Cornell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Columbia</td>\n",
              "      <td>Columbia University</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MIT</td>\n",
              "      <td>MIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Carnegie Mellon</td>\n",
              "      <td>Carnegie Mellon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Columbia</td>\n",
              "      <td>Columbia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Cornell</td>\n",
              "      <td>Cornell University</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>University of Central Florida</td>\n",
              "      <td>University of Central Florida, Brownsville Sch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       educ_inst  \\\n",
              "0                            NaN   \n",
              "1               Bowndoin College   \n",
              "2                        Cornell   \n",
              "3                       Columbia   \n",
              "4                            MIT   \n",
              "5                Carnegie Mellon   \n",
              "6                       Columbia   \n",
              "7                        Cornell   \n",
              "8  University of Central Florida   \n",
              "9                                  \n",
              "\n",
              "                       education_institution_llama33  \n",
              "0                 University of California, Berkeley  \n",
              "1                                    Bowdoin College  \n",
              "2                                       MIT, Cornell  \n",
              "3                                Columbia University  \n",
              "4                                                MIT  \n",
              "5                                    Carnegie Mellon  \n",
              "6                                           Columbia  \n",
              "7                                 Cornell University  \n",
              "8  University of Central Florida, Brownsville Sch...  \n",
              "9                                               none  "
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run the prompts\n",
        "r_llama33 = do_predictions(prompt_user_educinstit,\n",
        "                           df['text_combined'],\n",
        "                           \"meta-llama/llama-3.3-70b-instruct\" #test with a different model\n",
        "                           )\n",
        "# Add the result to the dataframe\n",
        "df.loc[:, \"education_institution_llama33\"] = [i.choices[0].message.content if i is not None else None for i in r_llama33] #same for the second model tested\n",
        "\n",
        "# Save the data\n",
        "df.to_csv(\"table_results.csv\")\n",
        "\n",
        "# Display\n",
        "df[[\"educ_inst\", \"education_institution_llama33\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4qKtEaXEgQ0"
      },
      "source": [
        "A raw accuracy yields catastrophic validation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ARcYabmEYgq",
        "outputId": "eca07cad-f9a9-4384-cd9b-a58fadfbb873"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.3)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(df[\"education_institution_llama33\"] == df[\"educ_inst\"]).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3zdwIiiYKsN"
      },
      "source": [
        "# Your turn to try!\n",
        "\n",
        "Try with a different model\n",
        "\n",
        "Try to better define the extraction format to limit the variation\n",
        "\n",
        "Try with the variable religion. Do you notice something?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp7VSX-GVzW-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8jIxT9_V0KH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvhwFyHMX-kJ"
      },
      "source": [
        "There are differences, but are they significant differences ? How to compute metrics ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjqNXrvJgMLv"
      },
      "source": [
        "# Taking into account variations\n",
        "\n",
        "Since the generative process generates free responses, we need to design a strategy to deal with them.\n",
        "\n",
        "Different strategies can be used:\n",
        "\n",
        "- systematic modification : lower case, remove punctuation\n",
        "- human judgment on disagreement to validate\n",
        "- LLM-as-a-judge with a new request to a LLM\n",
        "\n",
        "For the article, we used human-in-the-loop:\n",
        "\n",
        "1. A first comparison with the gold standard with simple automatic rules\n",
        "2. A human to judge if the disagreement is real (with 3 possibilities : disagreement, agreement, partial agreement)\n",
        "3. Computation of the metrics using the human loop results\n",
        "\n",
        "So we have 2 rules to decide if a prediction is correct:\n",
        "\n",
        "- it is the same string with small variations (1/2 different letters or punctuation)\n",
        "- if a human decides it is the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "RX5aKn6zIEOu",
        "outputId": "fb48c3f2-086e-40b1-943d-09439fceab1e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>educ_inst</th>\n",
              "      <th>education_institution_llama33</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>University of California, Berkeley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bowndoin College</td>\n",
              "      <td>Bowdoin College</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cornell</td>\n",
              "      <td>MIT, Cornell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Columbia</td>\n",
              "      <td>Columbia University</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MIT</td>\n",
              "      <td>MIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Carnegie Mellon</td>\n",
              "      <td>Carnegie Mellon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Columbia</td>\n",
              "      <td>Columbia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Cornell</td>\n",
              "      <td>Cornell University</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>University of Central Florida</td>\n",
              "      <td>University of Central Florida, Brownsville Sch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       educ_inst  \\\n",
              "0                            NaN   \n",
              "1               Bowndoin College   \n",
              "2                        Cornell   \n",
              "3                       Columbia   \n",
              "4                            MIT   \n",
              "5                Carnegie Mellon   \n",
              "6                       Columbia   \n",
              "7                        Cornell   \n",
              "8  University of Central Florida   \n",
              "9                                  \n",
              "\n",
              "                       education_institution_llama33  \n",
              "0                 University of California, Berkeley  \n",
              "1                                    Bowdoin College  \n",
              "2                                       MIT, Cornell  \n",
              "3                                Columbia University  \n",
              "4                                                MIT  \n",
              "5                                    Carnegie Mellon  \n",
              "6                                           Columbia  \n",
              "7                                 Cornell University  \n",
              "8  University of Central Florida, Brownsville Sch...  \n",
              "9                                               none  "
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reload the elements if needed for the comparison\n",
        "df_compare = df[[\"educ_inst\",\"education_institution_llama33\"]]\n",
        "df_compare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_0WdT6Y7Zmi"
      },
      "source": [
        "### Define a cleaning function to compare\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "WYB2t6NGTJuq"
      },
      "outputs": [],
      "source": [
        "import string # to get punctuation\n",
        "import Levenshtein # to measure the distance between strings\n",
        "import pandas as pd\n",
        "\n",
        "def clean(val:str):\n",
        "  \"\"\"\n",
        "  Clean strings\n",
        "  \"\"\"\n",
        "  if pd.isnull(val):\n",
        "    return None\n",
        "  # lower case without punctuation\n",
        "  val = val.lower().translate(str.maketrans('', '', string.punctuation)).replace(\"university\", \"\").replace(\"college\", \"\")\n",
        "  # empty answer variations\n",
        "  if val in [\"not mentioned\", \"none\"]:\n",
        "    val = None\n",
        "  return val\n",
        "\n",
        "def eval_equality(str1:str, str2:str, distance_max:int = 1):\n",
        "  \"\"\"\n",
        "  Define equality between 2 strings\n",
        "  \"\"\"\n",
        "  # clean the string using function defined above\n",
        "  str1 = clean(str1)\n",
        "  str2 = clean(str2)\n",
        "\n",
        "  # case with the None value\n",
        "  if (str1 is None and str2) or (str1 and str2 is None):\n",
        "    return False\n",
        "  if str1 is None and str2 is None:\n",
        "    return True\n",
        "\n",
        "  # test equality\n",
        "\n",
        "  # strict\n",
        "  if str1 == str2:\n",
        "    return True\n",
        "\n",
        "  # with distance_max letters difference\n",
        "  distance = Levenshtein.distance(str1, str2)\n",
        "  if distance <= distance_max:\n",
        "    return True\n",
        "\n",
        "  return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocL6D34J8RJ9"
      },
      "source": [
        "Add to the dataframe new columns with the post-processed values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "gQyPsZrCh5aG"
      },
      "outputs": [],
      "source": [
        "df_compare[\"education_institution_llama33_valid\"] = df_compare.apply(lambda x: eval_equality(x[\"educ_inst\"], x[\"education_institution_llama33\"]), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUn9REudIi8H"
      },
      "source": [
        "It is already better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI--UvVkIigb",
        "outputId": "c1e5360f-8b5b-4b63-8b80-9d49cee16308"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.6)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_compare[\"education_institution_llama33_valid\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZN8t4ic_hnk"
      },
      "source": [
        "Export only cases featuring disagreement in a file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "wtAgf35B8-Kq"
      },
      "outputs": [],
      "source": [
        "# for llama3.3\n",
        "table = df_compare[~df_compare[\"education_institution_llama33_valid\"]][[\"educ_inst\",\"education_institution_llama33\"]].reset_index()\n",
        "table[\"equal\"] = None\n",
        "table.to_excel(\"ie_education_institution_llama33_to_recode.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7irNfWwSf1ZJ"
      },
      "source": [
        "The annotator needs then to rename the file from to_recode to recoded [to recode => recoded], and enter something (1, or X) in the column \"equal\" if he/she juges that the extracted value match the gold standard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_hz-KEl_lQ6"
      },
      "source": [
        "Reload the file after changes (and rename to `ie_education_institution_llama33_recoded.xlsx`) and match it with the data to compute performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wg8U6bxZ93p0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "if Path(\"ie_education_institution_llama33_recoded.xlsx\").exists():\n",
        "    # read the human annotated file\n",
        "    table_reco = pd.read_excel(\"ie_education_institution_llama33_recoded.xlsx\")\n",
        "\n",
        "    # get the id of the element reco\n",
        "    idx_human_feedback = table_reco[table_reco[\"equal\"].notnull()].index\n",
        "    df_compare.loc[idx_human_feedback, \"education_institution_llama33_valid\"] = True\n",
        "else:\n",
        "    print(\"No human feedback available for llama3.3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "rmgxgKc3fOv6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.6)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_compare[\"education_institution_llama33_valid\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ842qPchMdh"
      },
      "source": [
        "For the categorical data, it is possible to use classical metrics (f1, ...). Since the generation + the human loop can judge the generated information as equal to the gold standard - even if it is not exactly the same string, and we must \"smooth\", post-process the data before proceding."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
